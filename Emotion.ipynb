{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VjMkEQmTicK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random as rnd\n",
        "import collections\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten,Dropout, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/kaggle/input/fer2013/train\"\n",
        "test_dir = \"/kaggle/input/fer2013/test\""
      ],
      "metadata": {
        "id": "GxI5P_47T0KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fer_ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(48, 48),    # Resize images\n",
        "    color_mode=\"grayscale\", # Convert to grayscale (or use \"rgb\" if needed)\n",
        "    batch_size=32,          # Set batch size\n",
        "    label_mode=\"categorical\",       # Use \"categorical\" for one-hot encoding\n",
        "    shuffle=True,            # Shuffle the dataset\n",
        "    validation_split=0.2,  # 20% of training data for validation\n",
        "    subset=\"training\",  # This dataset will be used for training\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "fer_ds_val = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(48, 48),    # Resize images\n",
        "    color_mode=\"grayscale\", # Convert to grayscale (or use \"rgb\" if needed)\n",
        "    batch_size=32,          # Set batch size\n",
        "    label_mode=\"categorical\",       # Use \"categorical\" for one-hot encoding\n",
        "    shuffle=True,            # Shuffle the dataset\n",
        "    validation_split=0.2,  # Use the same validation split\n",
        "    subset=\"validation\",  # This dataset will be used for validation\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "\n",
        "fer_ds_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(48, 48),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=32,\n",
        "    label_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "for images, labels in fer_ds_train.take(1):\n",
        "    print(\"Label shape:\", labels.shape)  # Should be (batch_size, num_classes)\n",
        "    print(\"Example label:\", labels.numpy()[0])  # Should look like [0, 0, 1, 0, 0]"
      ],
      "metadata": {
        "id": "LENT0Qp8T9MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = fer_ds_train.class_names\n",
        "\n",
        "print(\"Class names:\", class_names)  # Print to check"
      ],
      "metadata": {
        "id": "1r3ZkmOdT-PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(fer_ds_train))\n",
        "\n",
        "\n",
        "# Convert tensors to NumPy arrays\n",
        "image_batch_np = image_batch.numpy()\n",
        "label_batch_np = label_batch.numpy()\n",
        "\n",
        "# Randomly select 9 images from the batch\n",
        "random_indices = rnd.sample(range(len(image_batch_np)), 9)  # Pick 9 random indices\n",
        "random_images = [image_batch_np[i] for i in random_indices]\n",
        "random_labels = [class_names[np.argmax(label_batch_np[i])] for i in random_indices]\n",
        "\n",
        "# Plot the images\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(9):  # Show 9 images\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(random_images[i].squeeze(), cmap=\"gray\")  # Display grayscale image\n",
        "    plt.title(random_labels[i])  # Show class name\n",
        "    plt.axis(\"off\")  # Hide axis\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_BvROta8UBeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "fer_ds_train = fer_ds_train.map(lambda x, y: (x / 255.0, y)).cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "fer_ds_val = fer_ds_val.map(lambda x, y: (x / 255.0, y)).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "fer_ds_test = fer_ds_test.map(lambda x, y: (x / 255.0, y)).cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "_gGhXRM9UEMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Prevent overfitting\n",
        "    layers.Dense(7, activation='softmax')  # 7 classes for FER dataset\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yoBJrmmXUGcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "RDHuIUIfUJpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                            patience=2,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "metadata": {
        "id": "NA2_fsyNUOmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(fer_ds_train, validation_data=fer_ds_val, epochs=10, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "dnpgJSXrUPPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(fer_ds_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "idOhrk3aUTQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, accuracy, 'bo', label=\"Train_Acc\")\n",
        "plt.plot(epochs, val_accuracy, 'r', label=\"val_Acc\")\n",
        "plt.legend(loc='best', shadow=True)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'bo', label=\"Train_Loss\")\n",
        "plt.plot(epochs, val_loss, 'r', label=\"val_Loss\")\n",
        "plt.legend(loc='best', shadow=True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzGaq7TvUWN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(fer_ds_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "VnZ_F3XYUYpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probabilities to class indices\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "true_labels = np.concatenate([y.numpy() for _, y in fer_ds_test])\n",
        "true_labels = np.argmax(true_labels, axis=1)\n",
        "\n",
        "print(classification_report(true_labels, predicted_labels, zero_division=1))\n",
        "\n",
        "# Print an example\n",
        "print(f\"Predicted Emotion: {class_names[predicted_labels[0]]}\")\n",
        "print(f\"True Emotion: {class_names[true_labels[0]]}\")"
      ],
      "metadata": {
        "id": "kgUQDksBUbL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"CNN.h5\")\n",
        "model.save_weights(\"CNN.weights.h5\")"
      ],
      "metadata": {
        "id": "pbWzi2EXUdes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    'emotion': [class_names[label] for label in predicted_labels]\n",
        "})\n",
        "\n",
        "filenames = [f'image_{i}.jpg' for i in range(len(predicted_labels))]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'file': filenames,\n",
        "    'emotion': [class_names[label] for label in predicted_labels]\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created!\")"
      ],
      "metadata": {
        "id": "Yrddnsv6Ufi0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}